{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "transformers_new.ipynb의 사본",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7YsuH6V56J02"
      },
      "outputs": [],
      "source": [
        "import numpy as np                                                                             # model(x_train)은 model.forward(x_train)와 동일함.\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math, copy, time\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderDecoder(nn.Module):\n",
        "  def __init__(self,dmodel,Encoder,Decoder,input_embed,output_embed,Generator):                 #만일 init에서 encoder, edcoder 인자로해주면,(def __init__(self,dmodel,outputsize,encoder,decoder): 로써주면)\n",
        "                                                                                                 #나중에 EncoderDecoder 호출(사용)할 때, EncoderDecoder(Encoder(EncoderLayer(d_model, c(attn), c(ff), dropout), N...)이런식으로 초기화 해줘야함\n",
        "                                                                                                 #init에서 encoder decoder 인자로 하지 않으면, self에서 해줘야함\n",
        "    super(EncoderDecoder,self).__init__()                                                         # model(x_train)은 model.forward(x_train)와 동일함.\n",
        "\n",
        "    self.encoder=Encoder\n",
        "    self.decoder=Decoder\n",
        "    self.generator=Generator\n",
        "    self.input_embed=input_embed\n",
        "    self.output_embed=output_embed\n",
        "\n",
        "  def forward(self,input,input_mask,output,output_mask):\n",
        "    embedded_input=self.input_embed(input)\n",
        "    memory=self.encoder(embedded_input,False)\n",
        "    embedded_output=self.output_embed(output)\n",
        "    decoder_result=self.decoder(memory,embedded_output,False,True)\n",
        "    \n",
        "    decoder_result=self.generator(decoder_result)\n",
        "    return decoder_result.view(-1,decoder_result.size(-1))                                                       #decoder_result.view(-1,decoder_result.size(-1))   지우기 원래는 decoder result만 return\n",
        "\n",
        "\n",
        "class Generator(nn.Module):\n",
        "  def __init__(self,dmodel,outputsize):\n",
        "    super(Generator,self).__init__()\n",
        "    self.linear=nn.Linear(dmodel,outputsize)\n",
        "\n",
        "  def forward(self,x):\n",
        "      y=self.linear(x)\n",
        "      return F.softmax(y, dim=-1)                                               #행 방향으로 한다 dim=-1 차원을 제거한다는것,즉 열 차원을 제거하니, 행방향을 기준으로 계산,\n",
        "\n",
        "\n",
        "def clone(module,N):\n",
        "     \n",
        "  return nn.ModuleList([copy.deepcopy(module) for i in range(N)])  \n",
        "\n",
        "class Encoder(nn.Module):\n",
        "  def __init__(self,Sublayer,layer_num):\n",
        "    super(Encoder,self).__init__()\n",
        "    self.layers=clone(Sublayer,layer_num)\n",
        "    self.layer_num=layer_num\n",
        "\n",
        "\n",
        "  def forward(self,x,x_mask):\n",
        "    for layer in self.layers:\n",
        "      x=layer(x,x_mask)\n",
        "    return x                                                          \n",
        "\n",
        "class EncoderSublayer(nn.Module):\n",
        "  def __init__(self,dmodel,self_attention,feed_forward,dropout):      \n",
        "    super(EncoderSublayer,self).__init__()\n",
        "    self.Attention=self_attention       \n",
        "    self.FeedForward=feed_forward    \n",
        "    self.norm=nn.LayerNorm(dmodel)\n",
        "    self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "  def forward(self,x,x_mask):\n",
        "    y=self.norm(x+self.dropout(self.Attention(x,x,x,False)))\n",
        "    output=self.norm(y+self.FeedForward(y))\n",
        "\n",
        "    return output\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "  def __init__(self,Sublayer,layer_num):\n",
        "    super(Decoder,self).__init__()\n",
        "    self.layers=clone(Sublayer,layer_num)\n",
        "    self.layer_num=layer_num\n",
        "\n",
        "\n",
        "  def forward(self,memory,embedded_output,input_mask,output_mask):\n",
        "    for layer in self.layers:\n",
        "      x=layer(memory,embedded_output,input_mask,output_mask)\n",
        "    return x\n",
        "\n",
        "\n",
        "class DecoderSublayer(nn.Module):\n",
        "  def __init__(self,dmodel,attention,feed_forward,dropout):\n",
        "    super(DecoderSublayer,self).__init__()\n",
        "    self.attention=attention       #나중에 만들기\n",
        "    self.feedforward=feed_forward    #나중에 만들기\n",
        "    self.norm=nn.LayerNorm(dmodel)\n",
        "    self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "  def forward(self,memory,x,input_mask,output_mask):                            #x는 embedded output, Output_mask는 True, input은 false임\n",
        "    y=self.norm(x+self.dropout(self.attention(x,x,x,True)))\n",
        "    y=self.norm(y+self.dropout(self.attention(memory,memory,y,False)))\n",
        "    output=self.norm(y+self.feedforward(y))\n",
        "\n",
        "    return output\n",
        "\n",
        "\n",
        "\n",
        "#subsequent mask??\n",
        "\n",
        "class multihead_Attention(nn.Module):\n",
        "    def __init__(self,d_model, num_head,dropout=0.1):\n",
        "        super(multihead_Attention, self).__init__()\n",
        "        self.d_k=d_model//num_head                                               #d_q=d_k=d_v\n",
        "        self.num_head=num_head\n",
        "        self.Qlinear=nn.Linear(d_model,d_model)\n",
        "        self.Klinear=nn.Linear(d_model,d_model)\n",
        "        self.Vlinear=nn.Linear(d_model,d_model)\n",
        "        self.Olinear=nn.Linear(d_model,d_model)\n",
        "        \n",
        "        \n",
        "        self.dropout=nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self,query_input,key_input,value_input,is_mask):                              #encoder에선 input이 다 똑같은 tensor 들어옴, decoder의 multihead에선 쿼리,키는 encoder의 ouput을 받음   \n",
        "        batch_size=query_input.size(0)\n",
        "\n",
        "        Q=self.Qlinear(query_input).view(batch_size,-1,self.num_head,self.d_k).transpose(1,2)\n",
        "        K=self.Klinear(key_input).view(batch_size,-1,self.num_head,self.d_k).transpose(1,2)\n",
        "        V=self.Vlinear(value_input).view(batch_size,-1,self.num_head,self.d_k).transpose(1,2)\n",
        "        \n",
        "        attention_value=Self_Attention(query=Q,key=K,value=V,is_mask=is_mask,dropout=self.dropout)\n",
        "        multihead_attention_result = attention_value.transpose(1,2).contiguous().view(batch_size, -1, self.num_head * self.d_k)\n",
        "        \n",
        "        return multihead_attention_result\n",
        "\n",
        "\n",
        "        \n",
        "    \n",
        "\n",
        "        \n",
        "def Self_Attention(query,key,value,is_mask,dropout):\n",
        "        d_k=query.size(-1)\n",
        "\n",
        "        scale_dot_attention=torch.matmul(query,key.transpose(-1,-2))/math.sqrt(d_k)\n",
        "        \n",
        "        if is_mask==True:\n",
        "          seq_len=query.size()[-2]\n",
        "          mask=torch.triu(torch.ones(seq_len,seq_len),diagonal=1)*(-1.0e9)\n",
        "          scale_dot_attention= scale_dot_attention+mask\n",
        "\n",
        "          \n",
        "\n",
        "        attention_score=F.softmax(scale_dot_attention,dim=-1)\n",
        "\n",
        "        if dropout is not None:\n",
        "          attention_score = dropout(attention_score)\n",
        "        attention_value=torch.matmul(attention_score,value)\n",
        "        \n",
        "\n",
        "        return attention_value\n",
        "\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "  def __init__(self,dmodel,dropout=0.1):\n",
        "    super(FeedForward,self).__init__()\n",
        "    self.linear1=nn.Linear(dmodel,2048)\n",
        "    self.linear2=nn.Linear(2048,dmodel)\n",
        "    self.relu=F.relu\n",
        "    self.dropout=nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self,x):\n",
        "    y=self.linear1(x)\n",
        "    y=self.relu(y)\n",
        "    y=self.dropout(y)\n",
        "    y=self.linear2(y)\n",
        "\n",
        "    return y  \n",
        "\n",
        "\n",
        "class Embedding(nn.Module):\n",
        "  def __init__(self,dmodel,vocab):\n",
        "    super(Embedding,self).__init__()\n",
        "    self.embedding=nn.Embedding(vocab,dmodel)\n",
        "    self.dmodel=dmodel\n",
        "    #print(vocab)\n",
        "    #print(dmodel)\n",
        "\n",
        "  def forward(self,input):\n",
        "    print(input)\n",
        "    \n",
        "    y=self.embedding(input)*math.sqrt(self.dmodel)\n",
        "    seq_len=input.size()[1]\n",
        "    \n",
        "    position_encoding=self.Positional_Encoding(seq_len,self.dmodel)\n",
        "\n",
        "    return y+position_encoding\n",
        "\n",
        "  def Positional_Encoding(self,seq_len,dmodel):\n",
        "  \n",
        "  \n",
        "    position=torch.arange(seq_len).unsqueeze(1)\n",
        "    dimension=torch.arange(dmodel).unsqueeze(0)\n",
        "\n",
        "    angle=(position/np.power(10000,(2*(dimension//2))/dmodel))\n",
        "\n",
        "    pe=np.zeros((seq_len,dmodel))\n",
        "    pe[:,0::2]=np.sin(angle[:,0::2])\n",
        "    pe[:,1::2]=np.cos(angle[:,1::2])      \n",
        "\n",
        "    return torch.FloatTensor(pe)\n",
        "\n",
        "\n",
        "\n",
        "def make_model(source_vocab, target_vocab, N=6,d_model=512, d_ff=2048, h=8, dropout=0.1):     # N은 sublayer 개수, d_ff는 feed forward dimension\n",
        "  \n",
        "  c=copy.deepcopy\n",
        "  attention=multihead_Attention(d_model,h,dropout)\n",
        "  feedforward=FeedForward(d_model,dropout)\n",
        "\n",
        "  model=EncoderDecoder(d_model,Encoder(EncoderSublayer(d_model,c(attention),c(feedforward),dropout),N),\n",
        "                 Decoder(DecoderSublayer(d_model,c(attention),c(feedforward),dropout),N),\n",
        "                 Embedding(d_model,source_vocab),\n",
        "                 Embedding(d_model,target_vocab),\n",
        "                 Generator(d_model,target_vocab))\n",
        "  for p in model.parameters():\n",
        "        if p.dim() > 1:\n",
        "            # nn.init.xavier_uniform(p)\n",
        "            nn.init.xavier_uniform_(p)\n",
        "\n",
        "  return model\n",
        "\n",
        "\n",
        "#inputs = torch.LongTensor([[1,2,3,4]])  \n",
        "#outputs = torch.LongTensor([[1,2,3,4]])  \n",
        "\n",
        "#model = make_model(20,20,6,512, h=1)\n",
        "#output_probabilities = model(inputs,False,outputs,True)\n",
        "#print(output_probabilities.size())\n",
        "\n",
        "\n",
        "#여기서부터는 test\n",
        "\n",
        "def make_batch(sentences):\n",
        "    input_batch = [[src_vocab[n] for n in sentences[0].split()]]\n",
        "    output_batch = [[tgt_vocab[n] for n in sentences[1].split()]]\n",
        "    target_batch = [[tgt_vocab[n] for n in sentences[2].split()]]\n",
        "    return torch.LongTensor(input_batch), torch.LongTensor(output_batch), torch.LongTensor(target_batch)\n",
        "\n",
        "\n",
        "sentences = ['ich mochte ein bier P', 'S i want a beer', 'i want a beer E']\n",
        "\n",
        "# Transformer Parameters\n",
        "# Padding Should be Zero\n",
        "src_vocab = {'P': 0, 'ich': 1, 'mochte': 2, 'ein': 3, 'bier': 4}\n",
        "src_vocab_size = len(src_vocab)\n",
        "\n",
        "tgt_vocab = {'P': 0, 'i': 1, 'want': 2, 'a': 3, 'beer': 4, 'S': 5, 'E': 6}\n",
        "number_dict = {i: w for i, w in enumerate(tgt_vocab)}\n",
        "tgt_vocab_size = len(tgt_vocab)\n",
        "\n",
        "src_len = 5 # length of source\n",
        "tgt_len = 5 # length of target\n",
        "\n",
        "d_model = 512  # Embedding Size\n",
        "d_ff = 2048  # FeedForward dimension\n",
        "d_k = d_v = 64  # dimension of K(=Q), V\n",
        "n_layers = 6  # number of Encoder of Decoder Layer\n",
        "n_heads = 8  # number of heads in Multi-Head Attention\n",
        "\n",
        "model = make_model(source_vocab=src_vocab_size,target_vocab=tgt_vocab_size,N=6,d_model=512, d_ff=2048, h=8, dropout=0.1)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "enc_inputs, dec_inputs, target_batch = make_batch(sentences)\n",
        "\n",
        "for epoch in range(200):\n",
        "  optimizer.zero_grad()\n",
        "  \n",
        "  outputs = model(enc_inputs,False, dec_inputs,True)\n",
        "  loss = criterion(outputs, target_batch.contiguous().view(-1))\n",
        "  print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.6f}'.format(loss))\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n"
      ],
      "metadata": {
        "id": "UoFm_sVZ6Lp9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e21426d2-bdbc-4488-ce5b-eb9cd8006c1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0001 cost = 1.963730\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:189: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0002 cost = 1.772311\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0003 cost = 1.767583\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0004 cost = 1.794448\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0005 cost = 1.765237\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0006 cost = 1.737499\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0007 cost = 1.581072\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0008 cost = 1.557556\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0009 cost = 1.558209\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0010 cost = 1.554073\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0011 cost = 1.565090\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0012 cost = 1.565506\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0013 cost = 1.565569\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0014 cost = 1.565937\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0015 cost = 1.569030\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0016 cost = 1.588545\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0017 cost = 1.565508\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0018 cost = 1.565425\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0019 cost = 1.567956\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0020 cost = 1.565043\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0021 cost = 1.564871\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0022 cost = 1.556535\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0023 cost = 1.566222\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0024 cost = 1.548858\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0025 cost = 1.555003\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0026 cost = 1.564987\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0027 cost = 1.565412\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0028 cost = 1.565426\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0029 cost = 1.565423\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0030 cost = 1.565432\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0031 cost = 1.565408\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0032 cost = 1.565411\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0033 cost = 1.564949\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0034 cost = 1.565422\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0035 cost = 1.563944\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0036 cost = 1.558317\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0037 cost = 1.565422\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0038 cost = 1.565422\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0039 cost = 1.565420\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0040 cost = 1.561825\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0041 cost = 1.565422\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0042 cost = 1.565422\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0043 cost = 1.589556\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0044 cost = 1.565422\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0045 cost = 1.565422\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0046 cost = 1.565181\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0047 cost = 1.565422\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0048 cost = 1.565422\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0049 cost = 1.565422\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0050 cost = 1.565422\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0051 cost = 1.565422\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0052 cost = 1.565422\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0053 cost = 1.565704\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0054 cost = 1.565917\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0055 cost = 1.763394\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0056 cost = 1.565460\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0057 cost = 1.565422\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0058 cost = 1.567518\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0059 cost = 1.565422\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0060 cost = 1.565422\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0061 cost = 1.565420\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0062 cost = 1.562560\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0063 cost = 1.565422\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0064 cost = 1.565422\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0065 cost = 1.565422\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0066 cost = 1.565422\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0067 cost = 1.565422\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0068 cost = 1.565422\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0069 cost = 1.565422\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0070 cost = 1.565422\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0071 cost = 1.565422\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0072 cost = 1.565422\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0073 cost = 1.565422\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0074 cost = 1.565420\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0075 cost = 1.565422\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0076 cost = 1.565422\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0077 cost = 1.565422\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0078 cost = 1.565422\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0079 cost = 1.565422\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0080 cost = 1.565422\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0081 cost = 1.565407\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0082 cost = 1.565422\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0083 cost = 1.565421\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0084 cost = 1.565422\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0085 cost = 1.565268\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0086 cost = 1.565422\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0087 cost = 1.565422\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0088 cost = 1.565421\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0089 cost = 1.565422\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0090 cost = 1.565422\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0091 cost = 1.565381\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0092 cost = 1.565422\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0093 cost = 1.565422\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0094 cost = 1.565422\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0095 cost = 1.565422\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0096 cost = 1.565422\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0097 cost = 1.565409\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0098 cost = 1.565422\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0099 cost = 1.565422\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0100 cost = 1.565422\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0101 cost = 1.565422\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0102 cost = 1.565422\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0103 cost = 1.565422\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0104 cost = 1.563318\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0105 cost = 1.565421\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0106 cost = 1.565423\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0107 cost = 1.562758\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0108 cost = 1.565422\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0109 cost = 1.556776\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0110 cost = 1.563422\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0111 cost = 1.565409\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0112 cost = 1.565409\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0113 cost = 1.560538\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0114 cost = 1.565341\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0115 cost = 1.565422\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0116 cost = 1.565422\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0117 cost = 1.565422\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0118 cost = 1.564067\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0119 cost = 1.565422\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0120 cost = 1.565422\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0121 cost = 1.565400\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0122 cost = 1.565422\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0123 cost = 1.565172\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0124 cost = 1.565422\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0125 cost = 1.765337\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0126 cost = 1.565422\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0127 cost = 1.565422\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0128 cost = 1.588249\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0129 cost = 1.565422\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0130 cost = 1.565422\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0131 cost = 1.764603\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0132 cost = 1.555543\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0133 cost = 1.765416\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0134 cost = 1.762009\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0135 cost = 1.752936\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0136 cost = 1.565422\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0137 cost = 1.565422\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0138 cost = 1.560903\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0139 cost = 1.565422\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0140 cost = 1.565423\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0141 cost = 1.565422\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0142 cost = 1.565409\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0143 cost = 1.561996\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0144 cost = 1.565422\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0145 cost = 1.565422\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0146 cost = 1.565419\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0147 cost = 1.564966\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0148 cost = 1.565421\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0149 cost = 1.965152\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0150 cost = 1.561547\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0151 cost = 1.565357\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0152 cost = 1.565395\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0153 cost = 1.557620\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0154 cost = 1.565422\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0155 cost = 1.555536\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0156 cost = 1.565422\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0157 cost = 1.958090\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0158 cost = 1.566148\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0159 cost = 1.965422\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0160 cost = 1.634925\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0161 cost = 1.565302\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0162 cost = 1.556633\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0163 cost = 1.555583\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0164 cost = 1.557386\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0165 cost = 1.563620\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0166 cost = 1.565420\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0167 cost = 1.557558\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0168 cost = 1.565413\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0169 cost = 1.565163\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0170 cost = 1.763631\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0171 cost = 1.565431\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0172 cost = 1.559320\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0173 cost = 1.624279\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0174 cost = 1.566268\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0175 cost = 1.565413\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0176 cost = 1.564209\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0177 cost = 1.565400\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0178 cost = 1.556497\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0179 cost = 1.565175\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0180 cost = 1.564210\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0181 cost = 1.565255\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0182 cost = 1.765418\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0183 cost = 1.565333\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0184 cost = 1.565419\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0185 cost = 1.561117\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0186 cost = 1.631006\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0187 cost = 1.765422\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0188 cost = 1.965422\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0189 cost = 1.693593\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0190 cost = 1.567371\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0191 cost = 1.565426\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0192 cost = 1.765420\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0193 cost = 1.765412\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0194 cost = 1.565423\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0195 cost = 1.965422\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0196 cost = 1.565422\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0197 cost = 1.764370\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0198 cost = 1.765399\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0199 cost = 1.555749\n",
            "tensor([[1, 2, 3, 4, 0]])\n",
            "tensor([[5, 1, 2, 3, 4]])\n",
            "Epoch: 0200 cost = 1.592849\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "lpxp5OnV7EnG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}